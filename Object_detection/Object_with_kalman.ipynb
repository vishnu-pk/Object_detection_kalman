{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "net = cv2.dnn.readNet(\"yolov3.weights\",\"yolov3.cfg\")\n",
    "classes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"coco.names\",\"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "layer_names = net.getLayerNames()\n",
    "outputlayers = [layer_names[i[0] -1] for i in net.getUnconnectedOutLayers()]\n",
    "colors = np.random.uniform(0, 255, size=(len(classes), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KF(object):\n",
    "    def __init__(self,dt,acc_x,acc_y,sigma_x,sigma_y,sigma_acc):\n",
    "        \n",
    "        self.dt = dt\n",
    "        self.acc = np.array([[acc_x],[acc_y]])\n",
    "\n",
    "        # initialize the first state\n",
    "        self.X = np.zeros([4,1])\n",
    "        #initialize the covariance matrix by guessing a value. The guess can improve the accuracy of the initial predicted state\n",
    "        self.P = np.eye(4)\n",
    "        \n",
    "        #Now we need to define the matrics F, B, and H in order to have everything we need to the 2 Kalman filter equations\n",
    "        self.B = np.array([[0.5*(self.dt**2), 0],[0.5*(self.dt**2),0],[self.dt,0],[0,self.dt]])\n",
    "        self.F = np.array([[1, 0, self.dt, 0],[0, 1, 0, self.dt],[0, 0, 1, 0],[0, 0, 0, 1]])\n",
    "        self.H = np.array([[1, 0, 0, 0],[0, 1, 0, 0]])\n",
    "\n",
    "        #Later when we try to update the state, we will need the covariance matrics for the noises in the measurements and process\n",
    "        self.R = np.array([[sigma_x**2,0],[0,sigma_y**2]])\n",
    "        self.Q = np.array([[0.25*(self.dt**4), 0, 0.5*(self.dt**3), 0],[0,0.25*(self.dt**4), 0,0.5*(self.dt**3)],[0.5*(self.dt**3), 0, self.dt**2, 0],[0, 0.5*(self.dt**3), 0, self.dt**2]])*sigma_acc**2\n",
    "\n",
    "    def predict(self):\n",
    "        self.X = np.dot(self.F,self.X)+np.dot(self.B,self.acc)\n",
    "        self.P = np.dot(np.dot(self.F,self.P),self.F.T)+self.Q\n",
    "        return self.X\n",
    "\n",
    "    def update(self, z):\n",
    "        S = np.dot(np.dot(self.H,self.P),self.H.T)+self.R\n",
    "        K = np.dot(np.dot(self.P,self.H.T),np.linalg.inv(S))\n",
    "        self.P = np.dot((np.eye(4)-np.dot(K,self.H)),self.P)\n",
    "        self.X = self.X + np.dot(K, (z - np.dot(self.H, self.X)))\n",
    "        return self.X\n",
    "    \n",
    "    \n",
    "KalmanFilter = KF(0.5, 2, 3, 0.2, 0.3,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[208]\n",
      " [  3]]\n",
      "[[208]\n",
      " [  3]]\n",
      "[[208]\n",
      " [  3]]\n",
      "[[0]\n",
      " [4]\n",
      " [1]\n",
      " [5]\n",
      " [6]\n",
      " [3]]\n",
      "[[209]\n",
      " [  3]]\n",
      "[[209]\n",
      " [  3]]\n",
      "[[209]\n",
      " [  3]]\n",
      "[[0]\n",
      " [3]\n",
      " [4]\n",
      " [1]\n",
      " [5]\n",
      " [2]]\n",
      "[[206]\n",
      " [  3]]\n",
      "[[206]\n",
      " [  3]]\n",
      "[[206]\n",
      " [  3]]\n",
      "[[0]\n",
      " [3]\n",
      " [5]\n",
      " [4]\n",
      " [1]]\n",
      "[[208]\n",
      " [  1]]\n",
      "[[208]\n",
      " [  1]]\n",
      "[[208]\n",
      " [  1]]\n",
      "[[0]\n",
      " [2]\n",
      " [5]\n",
      " [3]\n",
      " [4]]\n",
      "[[208]\n",
      " [  1]]\n",
      "[[208]\n",
      " [  1]]\n",
      "[[208]\n",
      " [  1]]\n",
      "[[0]\n",
      " [2]\n",
      " [6]\n",
      " [4]\n",
      " [1]\n",
      " [5]\n",
      " [3]]\n",
      "[[209]\n",
      " [  3]]\n",
      "[[209]\n",
      " [  3]]\n",
      "[[209]\n",
      " [  3]]\n",
      "[[0]\n",
      " [2]\n",
      " [3]\n",
      " [5]\n",
      " [1]\n",
      " [6]]\n",
      "[[209]\n",
      " [  3]]\n",
      "[[209]\n",
      " [  3]]\n",
      "[[209]\n",
      " [  3]]\n",
      "[[0]\n",
      " [2]\n",
      " [4]\n",
      " [1]\n",
      " [5]\n",
      " [7]\n",
      " [3]]\n",
      "[[209]\n",
      " [  1]]\n",
      "[[209]\n",
      " [  1]]\n",
      "[[209]\n",
      " [  1]]\n",
      "[[2]\n",
      " [0]\n",
      " [4]\n",
      " [6]\n",
      " [5]\n",
      " [1]\n",
      " [3]\n",
      " [7]]\n",
      "[[209]\n",
      " [  1]]\n",
      "[[209]\n",
      " [  1]]\n",
      "[[209]\n",
      " [  1]]\n",
      "[[0]\n",
      " [6]\n",
      " [2]\n",
      " [5]\n",
      " [4]\n",
      " [1]\n",
      " [3]]\n",
      "[[211]\n",
      " [  3]]\n",
      "[[211]\n",
      " [  3]]\n",
      "[[211]\n",
      " [  3]]\n",
      "[[0]\n",
      " [5]\n",
      " [1]\n",
      " [3]\n",
      " [4]\n",
      " [6]]\n",
      "[[211]\n",
      " [  5]]\n",
      "[[211]\n",
      " [  5]]\n",
      "[[211]\n",
      " [  5]]\n",
      "[[8]\n",
      " [3]\n",
      " [0]\n",
      " [6]\n",
      " [7]\n",
      " [2]\n",
      " [1]\n",
      " [5]]\n",
      "[[211]\n",
      " [  2]]\n",
      "[[211]\n",
      " [  2]]\n",
      "[[211]\n",
      " [  2]]\n",
      "[[0]\n",
      " [3]\n",
      " [8]\n",
      " [7]\n",
      " [6]\n",
      " [1]\n",
      " [2]\n",
      " [5]]\n",
      "[[211]\n",
      " [  4]]\n",
      "[[211]\n",
      " [  4]]\n",
      "[[211]\n",
      " [  4]]\n",
      "[[0]\n",
      " [2]\n",
      " [6]\n",
      " [3]\n",
      " [4]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "   #Load Image\n",
    "vid = cv2.VideoCapture(\"obj.mp4\")\n",
    "i = 0\n",
    "while(1):\n",
    "    ret, img = vid.read()\n",
    "    i = i+1 \n",
    "    if i == 15:\n",
    "        continue\n",
    "    i = 0\n",
    "    img = cv2.resize(img, None, fx=0.4, fy =0.4)\n",
    "    frame = img\n",
    "    height, width, channels = img.shape\n",
    "    # Detecting objects\n",
    "    blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(outputlayers)\n",
    "    blurred = cv2.GaussianBlur(frame,(5,5),0)\n",
    "    canny = cv2.Canny(blurred,  50, 190, 3)\n",
    "    _, img_thresh = cv2.threshold(canny, 254, 255,cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Showing informations on the screen\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    centroids = []\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5:\n",
    "                # Object detected\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                (x, y) = center_x, center_y\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "\n",
    "                # Rectangle coordinates\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "                centroids.append(np.array([[int(x)], [int(y)]]))\n",
    "        if (len(centroids) > 0):\n",
    "            cv2.circle(frame, (int(centroids[0][0]), int(centroids[0][1])), 10, (0, 255, 0), 2)\n",
    "            State_predicted = KalmanFilter.predict()\n",
    "            (m,n) = State_predicted[0:2] # we only need the position values which are the first 2 elements in the X_k array\n",
    "            cv2.circle(frame, (m+3,n+3), 10, (0, 0, 255), 2)\n",
    "            print(centroids[0])\n",
    "            State_updated = KalmanFilter.update(centroids[0])\n",
    "            (a,b) = State_updated[0:2]\n",
    "            cv2.circle(frame, (a+6,b+6), 10, (255, 0, 0), 2)\n",
    "            cv2.putText(frame, \"position measured\", (centroids[0][0], centroids[0][1]), 0, 0.5, (0,255,0), 2)\n",
    "            cv2.putText(frame, \"position predicted\", (m+3, n+3), 0, 0.5, (0,0,255), 2)\n",
    "            cv2.putText(frame, \"position updated\", (a+6,b+6), 0, 0.5, (255,0,0), 2)\n",
    "     # Non-Max Supression\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "    print(indexes)\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    for i in range(len(boxes)):\n",
    "        if i in indexes:\n",
    "            x, y, w, h = boxes[i]\n",
    "            label = str(classes[class_ids[i]])\n",
    "            color = colors[i]\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
    "            cv2.putText(img, label, (x, y + 30), font, 3, color, 3)\n",
    "\n",
    "\n",
    "    cv2.imshow(\"image\",frame + img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            vid.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
